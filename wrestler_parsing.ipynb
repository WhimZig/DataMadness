{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b66d8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from parsing_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe021d",
   "metadata": {},
   "source": [
    "## To-Do\n",
    "* Tag Teams\n",
    "* Stables\n",
    "* Trainer\n",
    "* Finisher\n",
    "* Trademark Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f29c239-ea56-4fc0-a597-233f18acdc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getGeneralInfo(wrestlerID: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "#     \"\"\"\n",
    "#         Arguments:\n",
    "#             wrestlerID: wrestlingdata index for this wrestler, minimum is 1, maximum is 30195\n",
    "#\n",
    "#         Returns:\n",
    "#             GeneralInfo, Facts\n",
    "#     \"\"\"\n",
    "#     A = requests.get('https://www.wrestlingdata.com/index.php?befehl=bios&wrestler=%d'%wrestlerID)\n",
    "#     print(wrestlerID)\n",
    "#     wrestler = BeautifulSoup(A.text, 'html.parser')\n",
    "#     children = list(wrestler.find(title=\"General Information\").parent.parent.children)\n",
    "#     GeneralInfo = {c.attrs['title'] : [list(c.children)[3].text.strip('\\n')] for c in wrestler.find(title=\"General Information\").parent.parent.children if 'attrs' in c.__dict__ and 'title' in c.attrs}\n",
    "#     wrestler_name = list(wrestler.find(style=\"width:100%;\", cellpadding=\"4\", cellspacing=\"2\").children)[1].find(style=\"font-size: 14px;\").text.strip('\\n')\n",
    "#     res = pd.DataFrame(GeneralInfo, index = [wrestlerID])\n",
    "#     res['wrestler_name'] = [wrestler_name]\n",
    "#     tables2 = wrestler.find(title='Facts')\n",
    "#     B = pd.read_html(str(list(list(tables2.parent.parent.parent.parent.parent.children)[3].children)[1].table))\n",
    "#     return res.transpose(), B[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b21018d-f61b-4ccc-a1ac-3492ab091e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get50wrestlers(top_index: int) -> List[int]:\n",
    "#     \"\"\"\n",
    "#         Arguments:\n",
    "#             top_index: the index of the 'Rankings' page, minimum is 1, maximum is 105\n",
    "#\n",
    "#         Returns:\n",
    "#             A list of wrestlerID's corresponding to the list of wrestlers on the Rankings page with the given page number \"top_index\"\n",
    "#     \"\"\"\n",
    "#     B = requests.get('https://www.wrestlingdata.com/index.php?befehl=bios&letter=2&seite=%d'%top_index)\n",
    "#     wrestlerlist = BeautifulSoup(B.text, 'html.parser')\n",
    "#\n",
    "#     result_list = []\n",
    "#\n",
    "#     # I modified the parsing loop because it had issues in cases where the wrestler didn't have a hyperlink\n",
    "#     # This should work?\n",
    "#     for i in range(len(list(wrestlerlist.find(title=\"Liste der Wrestler\").children)[3:])):\n",
    "#         x = list(wrestlerlist.find(title=\"Liste der Wrestler\").children)[3:][i]\n",
    "#         if len(list(list(x.children)[2].children)) > 1:\n",
    "#             resulting_int = int(list(list(x.children)[2].children)[1].attrs['href'][32:])\n",
    "#         result_list.append(resulting_int)\n",
    "#\n",
    "#     return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96021c50-cead-45f1-a1e6-861fe3099225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getSample(sample_indices: List[int]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "#     \"\"\"\n",
    "#         Arguments:\n",
    "#             sample_indices: A list of wrestlerID's to be used as index for this sample\n",
    "#\n",
    "#         Returns:\n",
    "#             generalInfo, allFacts\n",
    "#     \"\"\"\n",
    "#     sample_GeneralInfo = [None for _ in range(len(sample_indices))]\n",
    "#     sample_Facts = [None for _ in range(len(sample_indices))]\n",
    "#     for i in range(len(sample_indices)):\n",
    "#         sample_GeneralInfo[i], sample_Facts[i] = getGeneralInfo(sample_indices[i])\n",
    "#     generalInfo = pd.concat([x.transpose() for x in sample_GeneralInfo])\n",
    "#\n",
    "#     res = pd.Index([])\n",
    "#     for x in sample_Facts:\n",
    "#         res = pd.concat([pd.Series(res), pd.Series(x[0].value_counts().index)])\n",
    "#     fact_columns = res.value_counts().index\n",
    "#     likely_columns = [x for x in fact_columns if len(x) < 40]\n",
    "#     ts = [None for _ in generalInfo.index]\n",
    "#     for i in range(len(generalInfo.index)):\n",
    "#         t = sample_Facts[i].groupby(0).agg(**{\"%d\"%generalInfo.index[i]: (1, set)})\n",
    "#         ts[i] = t.loc[t.index.intersection(likely_columns)].transpose()\n",
    "#     allFacts = pd.concat(ts)\n",
    "#     return generalInfo, allFacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e510ce48-04e0-4c6a-b180-c244fed12eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_wrestlers = open('wrestler_index_ordered.txt', 'r').read().split('\\n')\n",
    "# Last element is a '', so this is my bad way of removing it\n",
    "ranked_wrestlers.pop()\n",
    "ranked_wrestlers = [int(x) for x in ranked_wrestlers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "376b193d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_up_moves(elem):\n",
    "    if isinstance(elem, set):\n",
    "        return len(next(iter(elem)).replace(' and ', ',').split(','))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3d90b9d-c3b6-45d1-8ff7-08818e520614",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(ranked_wrestlers)\n",
    "\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "#\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "#\n",
    "# fact_counts.to_csv('Data/facts_counts_ranked.csv')\n",
    "#\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_ranked.csv')\n",
    "#\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc6f04b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# wrestler_info = pd.read_csv('Data/general_info_per_wrestler_ranked.csv')\n",
    "# wrestler_info.rename(columns={'Unnamed: 0': 'key'}, inplace=True)\n",
    "# wrestler_info.drop(['Height', 'Weight'], axis=1, inplace=True)\n",
    "# wrestler_info.astype({'Weight and Height': 'str', 'Birthplace' : 'str', 'Date of Birth': 'str', 'Debut': 'str', 'Date of Death': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3eafb3f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fact_counts = pd.read_csv('Data/facts_counts_ranked.csv')\n",
    "# fact_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45287b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TODO\n",
    "There's a temporary list of wrestlers. We've gotta parse them to clean the list up. Parsing will focus on the following:\n",
    "- Separating height and weight (we'll use kilos and meters for easiness sake)\n",
    "- Separating country of birth\n",
    "- Parsing date columns into datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aa1ba3b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This adds the country of birth as a column to the dataframe\n",
    "# birth_countries = wrestler_info[~wrestler_info['Birthplace'].isnull()]['Birthplace'].apply(lambda st: st[st.find(\"(\")+1:st.find(\")\")])\n",
    "#\n",
    "# wrestler_info['Birth Country'] = birth_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f069e18f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# height_and_weight = wrestler_info[~wrestler_info['Weight and Height'].isnull()]['Weight and Height'].str.split('at', expand=True)\n",
    "#\n",
    "# weight = height_and_weight[~height_and_weight[0].isnull()][0].apply(lambda st: st[st.find(\"(\")+1:st.find(\")\")])\n",
    "# weight = pd.to_numeric(weight.str[:-3], errors='coerce')\n",
    "# weight = weight[~weight.isnull()]\n",
    "# wrestler_info['Weight'] = weight\n",
    "#\n",
    "# height = height_and_weight[~height_and_weight[1].isnull()][1].apply(lambda st: st[st.find(\"(\")+1:st.find(\")\")])\n",
    "# height = pd.to_numeric(height.str[:-2], errors='coerce')\n",
    "# height = height[~height.isnull()]\n",
    "# wrestler_info['Height'] = height\n",
    "#\n",
    "# wrestler_info.drop(['Weight and Height'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "21802662",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dob = wrestler_info['Date of Birth'].str.replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "# dob = pd.to_datetime(dob, errors='coerce')\n",
    "#\n",
    "# debut = wrestler_info['Debut'].str.replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "# debut = pd.to_datetime(debut, errors='coerce')\n",
    "#\n",
    "# death = wrestler_info['Date of Death'].str.replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "# death = pd.to_datetime(dob, errors='coerce')\n",
    "#\n",
    "# wrestler_info['Date of Birth'] = dob\n",
    "# wrestler_info['Debut'] = debut\n",
    "# wrestler_info['Date of Death'] = death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5787ec5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# wrestler_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475cd992",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So, the wrestlers only have ratings if they have a certain number of votes.\n",
    "\n",
    "There's a bunch of wrestlers that are missing because of this. To fix this, I will manually parse this because suffering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a44c040",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First thing is reading in what are the indexes that we already have\n",
    "saved_indexes = ranked_wrestlers\n",
    "\n",
    "# Now to find the indexes that haven't been parsed\n",
    "all_valid_indexes = [i for i in range(1, 30196)]\n",
    "\n",
    "missing_indexes = list(set(all_valid_indexes) - set(saved_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14390a33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25213"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13d394ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(missing_indexes[:4000])\n",
    "#\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "#\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "#\n",
    "# fact_counts.to_csv('Data/facts_counts_missing_1.csv')\n",
    "#\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_missing_1.csv')\n",
    "#\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "803a7b8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(missing_indexes[4000:8000])\n",
    "#\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "#\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "#\n",
    "# fact_counts.to_csv('Data/facts_counts_missing_2.csv')\n",
    "#\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_missing_2.csv')\n",
    "#\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b371986",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(missing_indexes[8000:12000])\n",
    "#\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "#\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "#\n",
    "# fact_counts.to_csv('Data/facts_counts_missing_3.csv')\n",
    "#\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_missing_3.csv')\n",
    "#\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "58cfc1f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(missing_indexes[12000:16000])\n",
    "\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "\n",
    "# fact_counts.to_csv('Data/facts_counts_missing_4.csv')\n",
    "\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_missing_4.csv')\n",
    "\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "79b5b87d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(missing_indexes[16000:20000])\n",
    "\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "\n",
    "# fact_counts.to_csv('Data/facts_counts_missing_5.csv')\n",
    "\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_missing_5.csv')\n",
    "\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ad5bb04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(missing_indexes[20000:22000])\n",
    "\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "\n",
    "# fact_counts.to_csv('Data/facts_counts_missing_6.csv')\n",
    "\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_missing_6.csv')\n",
    "\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3391ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(missing_indexes[22000:24000])\n",
    "\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "\n",
    "# fact_counts.to_csv('Data/facts_counts_missing_7.csv')\n",
    "\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_missing_7.csv')\n",
    "\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "057dc6d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generalInfo, allFacts = getSample(missing_indexes[24000:])\n",
    "\n",
    "# fact_counts = pd.DataFrame({col: allFacts[col].apply(lambda x : x.__len__() if type(x) == set else 0) for col in allFacts.columns})\n",
    "\n",
    "# fact_counts['Trademark Moves'] = allFacts['Trademark Moves'].apply(lambda x: clean_up_moves(x))\n",
    "# fact_counts['Finisher'] = allFacts['Finisher'].apply(lambda x: clean_up_moves(x))\n",
    "\n",
    "# fact_counts.to_csv('Data/facts_counts_missing_8.csv')\n",
    "\n",
    "# generalInfo.to_csv('Data/general_info_per_wrestler_missing_8.csv')\n",
    "\n",
    "# print('Finished writing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cdd38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Joining up everything\n",
    "\n",
    "The previous code blocks separated the data for the sake of making parsing easier\n",
    "\n",
    "Now we've gotta go and merge them all togther into the final one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8a428180",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "wrestler_df = pd.read_csv('Data/general_info_per_wrestler_ranked.csv')\n",
    "wrestler_df_1 = pd.read_csv('Data/general_info_per_wrestler_missing_1.csv')\n",
    "wrestler_df_2 = pd.read_csv('Data/general_info_per_wrestler_missing_2.csv')\n",
    "wrestler_df_3 = pd.read_csv('Data/general_info_per_wrestler_missing_3.csv')\n",
    "wrestler_df_4 = pd.read_csv('Data/general_info_per_wrestler_missing_4.csv')\n",
    "wrestler_df_5 = pd.read_csv('Data/general_info_per_wrestler_missing_5.csv')\n",
    "wrestler_df_6 = pd.read_csv('Data/general_info_per_wrestler_missing_6.csv')\n",
    "wrestler_df_7 = pd.read_csv('Data/general_info_per_wrestler_missing_7.csv')\n",
    "wrestler_df_8 = pd.read_csv('Data/general_info_per_wrestler_missing_8.csv')\n",
    "\n",
    "# There's a high chance I effed up on the concatenation\n",
    "wrestler_merged = pd.concat([wrestler_df, wrestler_df_1, wrestler_df_2, wrestler_df_3, wrestler_df_4, wrestler_df_5, wrestler_df_6, wrestler_df_7, wrestler_df_8])\n",
    "\n",
    "wrestler_merged.rename(columns={'Unnamed: 0': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5a1cf5fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fact_df = pd.read_csv('Data/facts_counts_ranked.csv')\n",
    "fact_df_1 = pd.read_csv('Data/facts_counts_missing_1.csv')\n",
    "fact_df_2 = pd.read_csv('Data/facts_counts_missing_2.csv')\n",
    "fact_df_3 = pd.read_csv('Data/facts_counts_missing_3.csv')\n",
    "fact_df_4 = pd.read_csv('Data/facts_counts_missing_4.csv')\n",
    "fact_df_5 = pd.read_csv('Data/facts_counts_missing_5.csv')\n",
    "fact_df_6 = pd.read_csv('Data/facts_counts_missing_6.csv')\n",
    "fact_df_7 = pd.read_csv('Data/facts_counts_missing_7.csv')\n",
    "fact_df_8 = pd.read_csv('Data/facts_counts_missing_8.csv')\n",
    "\n",
    "fact_merged = pd.concat([fact_df, fact_df_1, fact_df_2, fact_df_3, fact_df_4, fact_df_5, fact_df_6, fact_df_7, fact_df_8])\n",
    "fact_merged.rename(columns={'Unnamed: 0': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2d114a78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This the merge of the dataframes\n",
    "merged_df = wrestler_merged.merge(fact_merged, on='id', how='left')\n",
    "\n",
    "# For some reason there are some that entries are repeated. I've checked them, the entire row is repeated\n",
    "# So we'll remove them for the sake of ease\n",
    "merged_df = merged_df[~merged_df.duplicated()]\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "# The last rows are kind of worthless, as they're comments that seem to apply to one wrestler that were kept\n",
    "# For some weird reason\n",
    "# So it's things like \"Owned by Billy Fox\", \"Nick, please tell us your email address\". Stuff that doesn't make sense\n",
    "merged_df = merged_df.iloc[:, :-14]\n",
    "\n",
    "merged_df.to_csv('all_info_wrestlers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
